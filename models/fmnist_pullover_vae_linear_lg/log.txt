15:12:31 Training device: cuda
15:12:31 BEGIN TRAINING Epoch [1/30]
15:12:32 TRAINING Epoch [1/30], Batch [16/47], Loss: 423.6842098236084
15:12:32 TRAINING Epoch [1/30], Batch [32/47], Loss: 382.10092544555664
15:12:32 BEGIN VALIDATION Epoch [1/30]
15:12:32 VALIDATION Epoch [1/30], Loss: 356.3064994812012
15:12:32 BEGIN TRAINING Epoch [2/30]
15:12:32 TRAINING Epoch [2/30], Batch [16/47], Loss: 344.47749519348145
15:12:32 TRAINING Epoch [2/30], Batch [32/47], Loss: 333.3351879119873
15:12:32 BEGIN VALIDATION Epoch [2/30]
15:12:32 VALIDATION Epoch [2/30], Loss: 330.54406356811523
15:12:32 BEGIN TRAINING Epoch [3/30]
15:12:32 TRAINING Epoch [3/30], Batch [16/47], Loss: 323.54710578918457
15:12:33 TRAINING Epoch [3/30], Batch [32/47], Loss: 323.0033950805664
15:12:33 BEGIN VALIDATION Epoch [3/30]
15:12:33 VALIDATION Epoch [3/30], Loss: 327.0723075866699
15:12:33 BEGIN TRAINING Epoch [4/30]
15:12:33 TRAINING Epoch [4/30], Batch [16/47], Loss: 321.0073299407959
15:12:33 TRAINING Epoch [4/30], Batch [32/47], Loss: 319.3161277770996
15:12:33 BEGIN VALIDATION Epoch [4/30]
15:12:33 VALIDATION Epoch [4/30], Loss: 324.56872177124023
15:12:33 BEGIN TRAINING Epoch [5/30]
15:12:33 TRAINING Epoch [5/30], Batch [16/47], Loss: 318.3460006713867
15:12:33 TRAINING Epoch [5/30], Batch [32/47], Loss: 320.93033027648926
15:12:33 BEGIN VALIDATION Epoch [5/30]
15:12:34 VALIDATION Epoch [5/30], Loss: 323.854434967041
15:12:34 BEGIN TRAINING Epoch [6/30]
15:12:34 TRAINING Epoch [6/30], Batch [16/47], Loss: 317.37542152404785
15:12:34 TRAINING Epoch [6/30], Batch [32/47], Loss: 317.6037902832031
15:12:34 BEGIN VALIDATION Epoch [6/30]
15:12:34 VALIDATION Epoch [6/30], Loss: 323.5557975769043
15:12:34 BEGIN TRAINING Epoch [7/30]
15:12:34 TRAINING Epoch [7/30], Batch [16/47], Loss: 317.71091651916504
15:12:34 TRAINING Epoch [7/30], Batch [32/47], Loss: 317.74869537353516
15:12:34 BEGIN VALIDATION Epoch [7/30]
15:12:34 VALIDATION Epoch [7/30], Loss: 322.68481826782227
15:12:34 BEGIN TRAINING Epoch [8/30]
15:12:34 TRAINING Epoch [8/30], Batch [16/47], Loss: 318.2421188354492
15:12:35 TRAINING Epoch [8/30], Batch [32/47], Loss: 315.9627857208252
15:12:35 BEGIN VALIDATION Epoch [8/30]
15:12:35 VALIDATION Epoch [8/30], Loss: 322.3299331665039
15:12:35 BEGIN TRAINING Epoch [9/30]
15:12:35 TRAINING Epoch [9/30], Batch [16/47], Loss: 315.64361000061035
15:12:35 TRAINING Epoch [9/30], Batch [32/47], Loss: 315.95970916748047
15:12:35 BEGIN VALIDATION Epoch [9/30]
15:12:35 VALIDATION Epoch [9/30], Loss: 322.09517669677734
15:12:35 BEGIN TRAINING Epoch [10/30]
15:12:35 TRAINING Epoch [10/30], Batch [16/47], Loss: 316.87548065185547
15:12:35 TRAINING Epoch [10/30], Batch [32/47], Loss: 315.0555820465088
15:12:35 BEGIN VALIDATION Epoch [10/30]
15:12:36 VALIDATION Epoch [10/30], Loss: 321.975399017334
15:12:36 BEGIN TRAINING Epoch [11/30]
15:12:36 TRAINING Epoch [11/30], Batch [16/47], Loss: 315.3954772949219
15:12:36 TRAINING Epoch [11/30], Batch [32/47], Loss: 315.68883895874023
15:12:36 BEGIN VALIDATION Epoch [11/30]
15:12:36 VALIDATION Epoch [11/30], Loss: 321.0845069885254
15:12:36 BEGIN TRAINING Epoch [12/30]
15:12:36 TRAINING Epoch [12/30], Batch [16/47], Loss: 315.1579170227051
15:12:36 TRAINING Epoch [12/30], Batch [32/47], Loss: 314.5068054199219
15:12:36 BEGIN VALIDATION Epoch [12/30]
15:12:36 VALIDATION Epoch [12/30], Loss: 320.6900444030762
15:12:36 BEGIN TRAINING Epoch [13/30]
15:12:37 TRAINING Epoch [13/30], Batch [16/47], Loss: 316.0359115600586
15:12:37 TRAINING Epoch [13/30], Batch [32/47], Loss: 314.14097023010254
15:12:37 BEGIN VALIDATION Epoch [13/30]
15:12:37 VALIDATION Epoch [13/30], Loss: 320.75014877319336
15:12:37 BEGIN TRAINING Epoch [14/30]
15:12:37 TRAINING Epoch [14/30], Batch [16/47], Loss: 316.60804748535156
15:12:37 TRAINING Epoch [14/30], Batch [32/47], Loss: 313.9435329437256
15:12:37 BEGIN VALIDATION Epoch [14/30]
15:12:37 VALIDATION Epoch [14/30], Loss: 320.2722358703613
15:12:37 BEGIN TRAINING Epoch [15/30]
15:12:37 TRAINING Epoch [15/30], Batch [16/47], Loss: 313.46759605407715
15:12:37 TRAINING Epoch [15/30], Batch [32/47], Loss: 313.9118175506592
15:12:37 BEGIN VALIDATION Epoch [15/30]
15:12:38 VALIDATION Epoch [15/30], Loss: 320.3031692504883
15:12:38 BEGIN TRAINING Epoch [16/30]
15:12:38 TRAINING Epoch [16/30], Batch [16/47], Loss: 314.8399600982666
15:12:38 TRAINING Epoch [16/30], Batch [32/47], Loss: 314.3870449066162
15:12:38 BEGIN VALIDATION Epoch [16/30]
15:12:38 VALIDATION Epoch [16/30], Loss: 319.3983688354492
15:12:38 BEGIN TRAINING Epoch [17/30]
15:12:38 TRAINING Epoch [17/30], Batch [16/47], Loss: 313.17356300354004
15:12:38 TRAINING Epoch [17/30], Batch [32/47], Loss: 314.23412895202637
15:12:38 BEGIN VALIDATION Epoch [17/30]
15:12:38 VALIDATION Epoch [17/30], Loss: 319.443416595459
15:12:38 BEGIN TRAINING Epoch [18/30]
15:12:39 TRAINING Epoch [18/30], Batch [16/47], Loss: 313.3561668395996
15:12:39 TRAINING Epoch [18/30], Batch [32/47], Loss: 312.697473526001
15:12:39 BEGIN VALIDATION Epoch [18/30]
15:12:39 VALIDATION Epoch [18/30], Loss: 319.20906829833984
15:12:39 BEGIN TRAINING Epoch [19/30]
15:12:39 TRAINING Epoch [19/30], Batch [16/47], Loss: 309.3507194519043
15:12:39 TRAINING Epoch [19/30], Batch [32/47], Loss: 315.28687477111816
15:12:39 BEGIN VALIDATION Epoch [19/30]
15:12:39 VALIDATION Epoch [19/30], Loss: 319.2878112792969
15:12:39 BEGIN TRAINING Epoch [20/30]
15:12:39 TRAINING Epoch [20/30], Batch [16/47], Loss: 313.08592987060547
15:12:39 TRAINING Epoch [20/30], Batch [32/47], Loss: 310.7343502044678
15:12:39 BEGIN VALIDATION Epoch [20/30]
15:12:40 VALIDATION Epoch [20/30], Loss: 318.89389419555664
15:12:40 BEGIN TRAINING Epoch [21/30]
15:12:40 TRAINING Epoch [21/30], Batch [16/47], Loss: 312.6578559875488
15:12:40 TRAINING Epoch [21/30], Batch [32/47], Loss: 313.83401107788086
15:12:40 BEGIN VALIDATION Epoch [21/30]
15:12:40 VALIDATION Epoch [21/30], Loss: 320.1891059875488
15:12:40 BEGIN TRAINING Epoch [22/30]
15:12:40 TRAINING Epoch [22/30], Batch [16/47], Loss: 311.78202629089355
15:12:40 TRAINING Epoch [22/30], Batch [32/47], Loss: 312.0559024810791
15:12:40 BEGIN VALIDATION Epoch [22/30]
15:12:40 VALIDATION Epoch [22/30], Loss: 318.98864364624023
15:12:40 BEGIN TRAINING Epoch [23/30]
15:12:41 TRAINING Epoch [23/30], Batch [16/47], Loss: 310.5096549987793
15:12:41 TRAINING Epoch [23/30], Batch [32/47], Loss: 313.93479919433594
15:12:41 BEGIN VALIDATION Epoch [23/30]
15:12:41 VALIDATION Epoch [23/30], Loss: 318.1605110168457
15:12:41 BEGIN TRAINING Epoch [24/30]
15:12:41 TRAINING Epoch [24/30], Batch [16/47], Loss: 311.68408393859863
15:12:41 TRAINING Epoch [24/30], Batch [32/47], Loss: 311.35350036621094
15:12:41 BEGIN VALIDATION Epoch [24/30]
15:12:41 VALIDATION Epoch [24/30], Loss: 317.8929862976074
15:12:41 BEGIN TRAINING Epoch [25/30]
15:12:41 TRAINING Epoch [25/30], Batch [16/47], Loss: 311.9890937805176
15:12:41 TRAINING Epoch [25/30], Batch [32/47], Loss: 312.3931198120117
15:12:42 BEGIN VALIDATION Epoch [25/30]
15:12:42 VALIDATION Epoch [25/30], Loss: 317.94687271118164
15:12:42 BEGIN TRAINING Epoch [26/30]
15:12:42 TRAINING Epoch [26/30], Batch [16/47], Loss: 311.0735607147217
15:12:42 TRAINING Epoch [26/30], Batch [32/47], Loss: 311.92456817626953
15:12:42 BEGIN VALIDATION Epoch [26/30]
15:12:42 VALIDATION Epoch [26/30], Loss: 317.5793762207031
15:12:42 BEGIN TRAINING Epoch [27/30]
15:12:42 TRAINING Epoch [27/30], Batch [16/47], Loss: 311.4669990539551
15:12:42 TRAINING Epoch [27/30], Batch [32/47], Loss: 311.1479797363281
15:12:42 BEGIN VALIDATION Epoch [27/30]
15:12:42 VALIDATION Epoch [27/30], Loss: 317.082462310791
15:12:42 BEGIN TRAINING Epoch [28/30]
15:12:43 TRAINING Epoch [28/30], Batch [16/47], Loss: 311.4631099700928
15:12:43 TRAINING Epoch [28/30], Batch [32/47], Loss: 309.3081455230713
15:12:43 BEGIN VALIDATION Epoch [28/30]
15:12:43 VALIDATION Epoch [28/30], Loss: 317.7320137023926
15:12:43 BEGIN TRAINING Epoch [29/30]
15:12:43 TRAINING Epoch [29/30], Batch [16/47], Loss: 310.1908130645752
15:12:43 TRAINING Epoch [29/30], Batch [32/47], Loss: 309.4252986907959
15:12:43 BEGIN VALIDATION Epoch [29/30]
15:12:43 VALIDATION Epoch [29/30], Loss: 317.4911460876465
15:12:43 BEGIN TRAINING Epoch [30/30]
15:12:43 TRAINING Epoch [30/30], Batch [16/47], Loss: 308.91880226135254
15:12:43 TRAINING Epoch [30/30], Batch [32/47], Loss: 312.2677917480469
15:12:44 BEGIN VALIDATION Epoch [30/30]
15:12:44 VALIDATION Epoch [30/30], Loss: 317.54896545410156
15:12:44 Training complete.
