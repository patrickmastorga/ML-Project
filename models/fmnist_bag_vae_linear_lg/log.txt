15:01:03 Training device: cuda
15:01:03 BEGIN TRAINING Epoch [1/30]
15:01:04 TRAINING Epoch [1/30], Batch [16/47], Loss: 436.548734664917
15:01:04 TRAINING Epoch [1/30], Batch [32/47], Loss: 400.2412643432617
15:01:04 BEGIN VALIDATION Epoch [1/30]
15:01:04 VALIDATION Epoch [1/30], Loss: 367.60372161865234
15:01:04 BEGIN TRAINING Epoch [2/30]
15:01:04 TRAINING Epoch [2/30], Batch [16/47], Loss: 359.1485538482666
15:01:04 TRAINING Epoch [2/30], Batch [32/47], Loss: 349.36528396606445
15:01:04 BEGIN VALIDATION Epoch [2/30]
15:01:04 VALIDATION Epoch [2/30], Loss: 327.303165435791
15:01:04 BEGIN TRAINING Epoch [3/30]
15:01:05 TRAINING Epoch [3/30], Batch [16/47], Loss: 320.796085357666
15:01:05 TRAINING Epoch [3/30], Batch [32/47], Loss: 317.85208320617676
15:01:05 BEGIN VALIDATION Epoch [3/30]
15:01:05 VALIDATION Epoch [3/30], Loss: 319.604305267334
15:01:05 BEGIN TRAINING Epoch [4/30]
15:01:05 TRAINING Epoch [4/30], Batch [16/47], Loss: 317.2906436920166
15:01:05 TRAINING Epoch [4/30], Batch [32/47], Loss: 316.3753547668457
15:01:05 BEGIN VALIDATION Epoch [4/30]
15:01:05 VALIDATION Epoch [4/30], Loss: 316.2004280090332
15:01:05 BEGIN TRAINING Epoch [5/30]
15:01:05 TRAINING Epoch [5/30], Batch [16/47], Loss: 315.49424934387207
15:01:05 TRAINING Epoch [5/30], Batch [32/47], Loss: 313.49022674560547
15:01:05 BEGIN VALIDATION Epoch [5/30]
15:01:06 VALIDATION Epoch [5/30], Loss: 316.68670654296875
15:01:06 BEGIN TRAINING Epoch [6/30]
15:01:06 TRAINING Epoch [6/30], Batch [16/47], Loss: 315.70448112487793
15:01:06 TRAINING Epoch [6/30], Batch [32/47], Loss: 312.3048896789551
15:01:06 BEGIN VALIDATION Epoch [6/30]
15:01:06 VALIDATION Epoch [6/30], Loss: 314.6126403808594
15:01:06 BEGIN TRAINING Epoch [7/30]
15:01:06 TRAINING Epoch [7/30], Batch [16/47], Loss: 312.1902275085449
15:01:06 TRAINING Epoch [7/30], Batch [32/47], Loss: 312.02853775024414
15:01:06 BEGIN VALIDATION Epoch [7/30]
15:01:06 VALIDATION Epoch [7/30], Loss: 314.98939514160156
15:01:06 BEGIN TRAINING Epoch [8/30]
15:01:07 TRAINING Epoch [8/30], Batch [16/47], Loss: 311.8704376220703
15:01:07 TRAINING Epoch [8/30], Batch [32/47], Loss: 311.59006690979004
15:01:07 BEGIN VALIDATION Epoch [8/30]
15:01:07 VALIDATION Epoch [8/30], Loss: 314.0957908630371
15:01:07 BEGIN TRAINING Epoch [9/30]
15:01:07 TRAINING Epoch [9/30], Batch [16/47], Loss: 313.9651107788086
15:01:07 TRAINING Epoch [9/30], Batch [32/47], Loss: 309.7106513977051
15:01:07 BEGIN VALIDATION Epoch [9/30]
15:01:07 VALIDATION Epoch [9/30], Loss: 314.25428009033203
15:01:07 BEGIN TRAINING Epoch [10/30]
15:01:07 TRAINING Epoch [10/30], Batch [16/47], Loss: 310.0738048553467
15:01:07 TRAINING Epoch [10/30], Batch [32/47], Loss: 312.71044540405273
15:01:07 BEGIN VALIDATION Epoch [10/30]
15:01:08 VALIDATION Epoch [10/30], Loss: 312.59993743896484
15:01:08 BEGIN TRAINING Epoch [11/30]
15:01:08 TRAINING Epoch [11/30], Batch [16/47], Loss: 310.830867767334
15:01:08 TRAINING Epoch [11/30], Batch [32/47], Loss: 309.2070541381836
15:01:08 BEGIN VALIDATION Epoch [11/30]
15:01:08 VALIDATION Epoch [11/30], Loss: 312.0475845336914
15:01:08 BEGIN TRAINING Epoch [12/30]
15:01:08 TRAINING Epoch [12/30], Batch [16/47], Loss: 311.87073516845703
15:01:08 TRAINING Epoch [12/30], Batch [32/47], Loss: 310.6843204498291
15:01:08 BEGIN VALIDATION Epoch [12/30]
15:01:08 VALIDATION Epoch [12/30], Loss: 311.7826957702637
15:01:08 BEGIN TRAINING Epoch [13/30]
15:01:09 TRAINING Epoch [13/30], Batch [16/47], Loss: 310.2461395263672
15:01:09 TRAINING Epoch [13/30], Batch [32/47], Loss: 309.3496799468994
15:01:09 BEGIN VALIDATION Epoch [13/30]
15:01:09 VALIDATION Epoch [13/30], Loss: 311.6409339904785
15:01:09 BEGIN TRAINING Epoch [14/30]
15:01:09 TRAINING Epoch [14/30], Batch [16/47], Loss: 307.2017002105713
15:01:09 TRAINING Epoch [14/30], Batch [32/47], Loss: 312.38678550720215
15:01:09 BEGIN VALIDATION Epoch [14/30]
15:01:09 VALIDATION Epoch [14/30], Loss: 311.716495513916
15:01:09 BEGIN TRAINING Epoch [15/30]
15:01:09 TRAINING Epoch [15/30], Batch [16/47], Loss: 306.78814125061035
15:01:09 TRAINING Epoch [15/30], Batch [32/47], Loss: 311.8099880218506
15:01:10 BEGIN VALIDATION Epoch [15/30]
15:01:10 VALIDATION Epoch [15/30], Loss: 311.6548843383789
15:01:10 BEGIN TRAINING Epoch [16/30]
15:01:10 TRAINING Epoch [16/30], Batch [16/47], Loss: 308.3405590057373
15:01:10 TRAINING Epoch [16/30], Batch [32/47], Loss: 309.9379253387451
15:01:10 BEGIN VALIDATION Epoch [16/30]
15:01:10 VALIDATION Epoch [16/30], Loss: 310.9874038696289
15:01:10 BEGIN TRAINING Epoch [17/30]
15:01:10 TRAINING Epoch [17/30], Batch [16/47], Loss: 309.933141708374
15:01:10 TRAINING Epoch [17/30], Batch [32/47], Loss: 309.6122455596924
15:01:10 BEGIN VALIDATION Epoch [17/30]
15:01:10 VALIDATION Epoch [17/30], Loss: 310.70742416381836
15:01:10 BEGIN TRAINING Epoch [18/30]
15:01:11 TRAINING Epoch [18/30], Batch [16/47], Loss: 308.27521324157715
15:01:11 TRAINING Epoch [18/30], Batch [32/47], Loss: 309.804105758667
15:01:11 BEGIN VALIDATION Epoch [18/30]
15:01:11 VALIDATION Epoch [18/30], Loss: 310.3691825866699
15:01:11 BEGIN TRAINING Epoch [19/30]
15:01:11 TRAINING Epoch [19/30], Batch [16/47], Loss: 307.8606586456299
15:01:11 TRAINING Epoch [19/30], Batch [32/47], Loss: 305.87811279296875
15:01:11 BEGIN VALIDATION Epoch [19/30]
15:01:11 VALIDATION Epoch [19/30], Loss: 311.58312606811523
15:01:11 BEGIN TRAINING Epoch [20/30]
15:01:11 TRAINING Epoch [20/30], Batch [16/47], Loss: 306.30821990966797
15:01:11 TRAINING Epoch [20/30], Batch [32/47], Loss: 309.59199714660645
15:01:12 BEGIN VALIDATION Epoch [20/30]
15:01:12 VALIDATION Epoch [20/30], Loss: 309.86560821533203
15:01:12 BEGIN TRAINING Epoch [21/30]
15:01:12 TRAINING Epoch [21/30], Batch [16/47], Loss: 309.40150451660156
15:01:12 TRAINING Epoch [21/30], Batch [32/47], Loss: 307.32844734191895
15:01:12 BEGIN VALIDATION Epoch [21/30]
15:01:12 VALIDATION Epoch [21/30], Loss: 309.675968170166
15:01:12 BEGIN TRAINING Epoch [22/30]
15:01:12 TRAINING Epoch [22/30], Batch [16/47], Loss: 308.9487991333008
15:01:12 TRAINING Epoch [22/30], Batch [32/47], Loss: 306.91541290283203
15:01:12 BEGIN VALIDATION Epoch [22/30]
15:01:13 VALIDATION Epoch [22/30], Loss: 309.7846870422363
15:01:13 BEGIN TRAINING Epoch [23/30]
15:01:13 TRAINING Epoch [23/30], Batch [16/47], Loss: 306.7671012878418
15:01:13 TRAINING Epoch [23/30], Batch [32/47], Loss: 304.9241142272949
15:01:13 BEGIN VALIDATION Epoch [23/30]
15:01:13 VALIDATION Epoch [23/30], Loss: 310.91648864746094
15:01:13 BEGIN TRAINING Epoch [24/30]
15:01:13 TRAINING Epoch [24/30], Batch [16/47], Loss: 306.6186275482178
15:01:13 TRAINING Epoch [24/30], Batch [32/47], Loss: 305.8677215576172
15:01:13 BEGIN VALIDATION Epoch [24/30]
15:01:13 VALIDATION Epoch [24/30], Loss: 309.32258224487305
15:01:13 BEGIN TRAINING Epoch [25/30]
15:01:13 TRAINING Epoch [25/30], Batch [16/47], Loss: 306.500545501709
15:01:14 TRAINING Epoch [25/30], Batch [32/47], Loss: 305.8978443145752
15:01:14 BEGIN VALIDATION Epoch [25/30]
15:01:14 VALIDATION Epoch [25/30], Loss: 309.6609115600586
15:01:14 BEGIN TRAINING Epoch [26/30]
15:01:14 TRAINING Epoch [26/30], Batch [16/47], Loss: 303.02297592163086
15:01:14 TRAINING Epoch [26/30], Batch [32/47], Loss: 308.107213973999
15:01:14 BEGIN VALIDATION Epoch [26/30]
15:01:14 VALIDATION Epoch [26/30], Loss: 308.5702209472656
15:01:14 BEGIN TRAINING Epoch [27/30]
15:01:14 TRAINING Epoch [27/30], Batch [16/47], Loss: 306.40749168395996
15:01:14 TRAINING Epoch [27/30], Batch [32/47], Loss: 305.57469940185547
15:01:14 BEGIN VALIDATION Epoch [27/30]
15:01:15 VALIDATION Epoch [27/30], Loss: 309.3812789916992
15:01:15 BEGIN TRAINING Epoch [28/30]
15:01:15 TRAINING Epoch [28/30], Batch [16/47], Loss: 307.11869049072266
15:01:15 TRAINING Epoch [28/30], Batch [32/47], Loss: 302.6840934753418
15:01:15 BEGIN VALIDATION Epoch [28/30]
15:01:15 VALIDATION Epoch [28/30], Loss: 309.49609375
15:01:15 BEGIN TRAINING Epoch [29/30]
15:01:15 TRAINING Epoch [29/30], Batch [16/47], Loss: 305.2135200500488
15:01:15 TRAINING Epoch [29/30], Batch [32/47], Loss: 307.43902015686035
15:01:15 BEGIN VALIDATION Epoch [29/30]
15:01:15 VALIDATION Epoch [29/30], Loss: 309.5807342529297
15:01:15 BEGIN TRAINING Epoch [30/30]
15:01:16 TRAINING Epoch [30/30], Batch [16/47], Loss: 303.9520568847656
15:01:16 TRAINING Epoch [30/30], Batch [32/47], Loss: 304.60103034973145
15:01:16 BEGIN VALIDATION Epoch [30/30]
15:01:16 VALIDATION Epoch [30/30], Loss: 308.9519691467285
15:01:16 Training complete.
